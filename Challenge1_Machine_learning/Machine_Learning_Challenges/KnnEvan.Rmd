---
title: "LogitMitch"
author: "Evan Wiebe"
date: "10/7/2023"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# pull data
library(readr)
raw_test <- read_csv("Mscs 341 F23/Project/Mitch, Evan, Adam/Data/sampled_data_test.csv")
raw_train <- read_csv("Mscs 341 F23/Project/Mitch, Evan, Adam/Data/sampled_data_train.csv")

# package requirements
library(dplyr)
library(tidyverse)
library(tidymodels)
library(viridis)
library(yardstick)

library(caret)
library(dslabs)

```


```{r echo=FALSE}

# Plots a digit as text matrix on the terminal
plot_text <- function(image) {
  a_digit <- matrix(image, nrow=28)
  even_pos <- seq(4,24,2)
  (a_digit[even_pos,even_pos])
}

# Plots a digit as an image
plot_digit <- function(image) {
  a_digit <- matrix(image, nrow=28)
  image(a_digit[,28:1])
}

# This function outputs a contrasted image 
# Notice an image is represented as a vector of 784 number from 0 to 255.
contrast_digit <- function(image){
  dark_idx = (image>128)
  image[dark_idx]=255   # Turn dark pixel indexes to 255
  image[!dark_idx]=0    # Turn non-dark pixel indexes to 0 (we use symbol !)
  return (image)
}

# This function calculates the number of dark pixels from an image
# Notice an image is represented as a vector of 784 number from 0 to 255.
count_dark_pixels <- function (image){
  dark_idx <- image>128
  num_pixels <- sum(dark_idx)
  return(num_pixels)
}

count_light_pixels <- function (image){
  light_idx <- image<128
  num_pixels <- sum(light_idx)
  return(num_pixels)
}

# This function returns a matrix with all the images corresponding to a digit (0-9) 
# from your mnist training dataset.
# The matrix will have 784 columns and the number of rows corresponds to the
# number of images
get_image_train_digit <- function (digit) {
  idx <- mnist$train$labels==digit
  images <- mnist$train$images[idx,]
  return (images)
}

# This function returns a matrix with all the images corresponding to a digit (0-9) 
# from your mnist testing dataset.
# The matrix will have 784 columns and the number of rows corresponds to the
# number of images
get_image_test_digit <- function (digit) {
  idx <- mnist$test$labels==digit
  images <- mnist$test$images[idx,]
  return (images)
}
```



```{r}
# Data manipulation.
# we need the output as a factor for classification.
test_tbl <- raw_test %>%
  mutate(Number = as.factor(Number))
  
train_tbl <- raw_train %>%
  mutate(Number = as.factor(Number))

# model building.
```


```{r}
#kNear=5
#knn_model <- knn3(y~x_1+x_2, data=train_tbl, k=kNear)
# set our recipe.


calc_error <- function(kNear, train_tbl, test_tbl) {
  
  knn_model <- knn3(Number ~ Size + Dark, data = train_tbl, k = 1)
  
  pred <- predict(knn_model, newdata = test_tbl)
  
  accuracy_value <- accuracy(data = test_tbl, estimate = .pred)
  
  return(accuracy_value)
}


calc_error2 <- function(kNear, train_tbl, test_tbl) {
  
  knn_model <- knn3(Number ~ Size + Dark, data = train_tbl, k = kNear)
  
  pred_prob <- predict(knn_model, newdata = test_tbl, type = "prob")
  
  pred_class <- ifelse(pred_prob[, 2] > 0.5, 1, 0)  # Assuming binary classification
  
  accuracy_value <- mean(pred_class == test_tbl$Number)
  
  return(accuracy_value)
}


calc_error4 <- function(kNear, train_tbl, test_tbl) {
  
  knn_model <- knn3(Number ~ Size + Dark, data = train_tbl, k = kNear)
  pred <- predict(knn_model, test_tbl, type="class") 
  
  mean (pred!=test_tbl$Number)
}




error_test <- vector(length = 100) 
for(i in 1:100){
  error_test[i] <- calc_error4(i, train_tbl, test_tbl)
}
error_tbl <- tibble (k=1:100,
                     accuracy = error_test)

error_tbl %>%
  ggplot(aes(x=k, y=accuracy)) +
  geom_line()

min_k_tbl <- error_tbl %>% 
  slice_max(accuracy)
min_k_tbl
```


```{r}
NumberRecipe <- 
  recipe(Number ~ Size + Dark, data=train_tbl)

# set our model type.

Knn_model <- nearest_neighbor(neighbors = min_k_tbl$k) %>%
  set_engine("kknn") %>%
  set_mode("classification")

# work flow.
Knn_wflow <- workflow() %>%
  add_recipe(NumberRecipe) %>% # mix recipe and model
  add_model(Knn_model) 

# fit the model.
Knn_fit_digit <- fit(Knn_wflow, train_tbl)
```


We now need to test our model.
```{r}
# table to evaluate our table
augmented_test <-augment(Knn_fit_digit, test_tbl)

#confusion matrix
augment(Knn_fit_digit, test_tbl)%>%
  conf_mat(Number, .pred_class)

# accuracy
augmented_test%>%
  accuracy(Number, .pred_class)

#sensitivity
augmented_test%>%
  sens(Number, .pred_class)

#specificity
augmented_test%>%
  yardstick::spec(Number, .pred_class)
```


```{r}
# Decision boundary

#find range of size
range(augmented_test$Size)
# gridvec1 as range of size (unit of 1 increase)
gridvec1 <- c(4:20)

#find range of dark pixels top half
range(augmented_test$Dark)
# gridvec2 as range of size (unit of 1 increase)
gridvec2 <- c(12:67)

# grid of theoretical values 
(grid_tbl <- expand_grid(Size=gridvec1, Dark=gridvec2))

# get the graph
augment(Knn_fit_digit, grid_tbl)%>% # percentages
ggplot(mapping = aes(x = Size, y = Dark, z = .pred_4, fill = .pred_4)) +
  geom_raster() +
  stat_contour(breaks=c(0.5), color="darkolivegreen1") + #bayes boundary
  scale_fill_viridis(option="magma")
```
```

